#!/usr/bin/env python3
"""
Export a unified TSV for heatmap visualization from a per‑puzzle Excel workbook
generated by run_fingernaat_pipeline.py (interactions sheet).

It standardizes columns to the schema used by
visualize_fingernaat_heatmap.py:
 - mandatory columns: Source, Ligand_name (optional), is_solution
 - feature columns named like '1:A#HB', '2:A#HAL', etc., or canonical
   '<sol_chain>:<sol_res>|<pred_chain>:<pred_res>#HB' when pocket mapping
   is available.

Usage:
  python bin/fingeRNAt/export_heatmap_tsv.py \
    --xlsx fingernaat_pipeline_outputs/PZ43/PZ43_fingernaat_results.xlsx \
    --sheet interactions \
    --out  fingernaat_pipeline_outputs/PZ43/fingernaat_summary_results.tsv
"""

import argparse
import sys
from pathlib import Path
import re

import pandas as pd


SCRIPT_ROOT = Path(__file__).resolve().parents[2]
MODULE_DIR = Path(__file__).resolve().parent
for p in (SCRIPT_ROOT, MODULE_DIR):
    if str(p) not in sys.path:
        sys.path.insert(0, str(p))

import pocket_index_utils as pocket_utils

# Cache for short-name mappings loaded from Puzzles/list/PZxx.list
_SHORT_NAME_MAP: dict[str, dict[str, str]] = {}



def normalize_feature_columns(df: pd.DataFrame) -> pd.DataFrame:
    rename_map = {}
    for c in df.columns:
        if isinstance(c, str):
            # Expect patterns like 'rna.pdb#1:A#HB' -> '1:A#HB'
            m = re.search(r"(\d+:[A-Za-z])#(.+)$", c)
            if m:
                newc = m.group(1) + '#' + m.group(2)
                rename_map[c] = newc
    if rename_map:
        df = df.rename(columns=rename_map)
    return df


def build_source_label(row: pd.Series) -> str:
    parts: list[str] = []

    puzzle = str(row.get("puzzle", "")).strip()
    if puzzle:
        parts.append(puzzle)

    src = str(row.get("source_pdb", "")).strip()
    if src:
        # Require a list file per puzzle; no fallback at file level.
        # 若没有对应 list 文件则直接报错，提醒补齐配置。
        if not puzzle:
            raise RuntimeError("Missing 'puzzle' column while building Source label; cannot apply short-name mapping.")
        if puzzle not in _SHORT_NAME_MAP:
            lst = SCRIPT_ROOT / "Puzzles" / "list" / f"{puzzle}.list"
            if not lst.exists():
                raise RuntimeError(f"Short-name list file not found for puzzle {puzzle}: {lst}")
            mapping: dict[str, str] = {}
            for raw in lst.read_text().splitlines():
                line = raw.strip()
                if not line or line.startswith("#"):
                    continue
                parts_line = line.split()
                if len(parts_line) < 2:
                    continue
                fname, short = parts_line[0].strip(), parts_line[1].strip()
                if not fname or not short:
                    continue
                # Map both with and without extension
                mapping[fname] = short
                mapping[Path(fname).name] = short
                mapping[Path(fname).stem] = short
            _SHORT_NAME_MAP[puzzle] = mapping
        mapping = _SHORT_NAME_MAP[puzzle]
        short_src = mapping.get(src) or mapping.get(Path(src).name) or mapping.get(Path(src).stem) or src
        parts.append(short_src)

    if "model_id" in row:
        parts.append(f"m{row['model_id']}")
    res = []
    for k in ('resname','chain','resseq','icode','occurrence'):
        if k in row and pd.notna(row[k]) and row[k] != '':
            res.append(str(row[k]))
    if res:
        parts.append('lig:' + ':'.join(res))
    return '|'.join(parts) if parts else str(row.get('Ligand_name','NA'))


def _infer_puzzle_from_xlsx(xlsx: Path, df: pd.DataFrame) -> str:
    """Infer puzzle name from DataFrame or XLSX filename."""
    if 'puzzle' in df.columns:
        vals = [str(v) for v in df['puzzle'].dropna().unique() if str(v)]
        if len(vals) == 1:
            return vals[0]
    stem = xlsx.stem
    # Assume filenames like PZ25_fingernaat_results.xlsx
    return stem.split('_', 1)[0]


def _infer_solution_stem(df: pd.DataFrame) -> str:
    """Infer solution PDB stem from rows with is_solution==1."""
    if 'is_solution' not in df.columns:
        return ""
    try:
        sol = df[df['is_solution'] == 1]
    except Exception:
        return ""
    if sol.empty:
        return ""
    row = sol.iloc[0]
    if 'source_pdb' in row and isinstance(row['source_pdb'], str):
        return Path(str(row['source_pdb'])).stem
    # Fallback: parse from Source label if possible
    src = str(row.get('Source', ''))
    parts = src.split('|')
    if len(parts) >= 2:
        return Path(parts[1]).stem
    return ""


def _load_solution_resnames(puzzle: str, sol_stem: str) -> dict:
    """
    Load solution residue names from PDB and build a mapping:
      (chain, resseq) -> one-letter base code (A/C/G/U/T/…).

    This is used purely for labelling canonical pocket axes; failure to load
    falls back to labels without base letters.
    """
    candidates = [
        SCRIPT_ROOT / "Puzzles" / "solution" / puzzle / f"{sol_stem}.pdb",
        SCRIPT_ROOT / "PuzzlesBACKUP" / "solution" / puzzle / f"{sol_stem}.pdb",
    ]
    pdb_path: Path | None = None
    for p in candidates:
        if p.exists():
            pdb_path = p
            break
    if pdb_path is None:
        return {}

    def _one_letter(resname: str) -> str:
        r = resname.strip().upper()
        if not r:
            return ""
        mapping = {
            "A": "A",
            "C": "C",
            "G": "G",
            "U": "U",
            "T": "T",
            "I": "I",
            "DA": "A",
            "DC": "C",
            "DG": "G",
            "DT": "T",
            "DI": "I",
        }
        if r in mapping:
            return mapping[r]
        # Default: first letter of residue name
        return r[0]

    mapping: dict[tuple[str, int], str] = {}
    try:
        for line in pdb_path.read_text().splitlines():
            if not line.startswith(("ATOM", "HETATM")):
                continue
            resname = line[17:20].strip()
            chain = line[21].strip()
            resseq_str = line[22:26].strip()
            if not chain or not resseq_str:
                continue
            try:
                resseq = int(resseq_str)
            except Exception:
                continue
            key = (chain, resseq)
            if key in mapping:
                continue
            mapping[key] = _one_letter(resname)
    except Exception:
        return {}
    return mapping


def _format_pocket_label(
    sol_chain: str,
    sol_res: int,
    pred_chain: str,
    pred_res: int,
    sol_resnames: dict,
    single_chain_mode: bool,
) -> str:
    """
    Build a human‑readable canonical pocket label.

    single_chain_mode=True 且链相同时：
      17G|1G

    多链或链不一致时：
      A:17G|B:1G
    """
    base = sol_resnames.get((sol_chain, sol_res), "")
    if single_chain_mode and sol_chain == pred_chain:
        if base:
            left = f"{sol_res}{base}"
            right = f"{pred_res}{base}"
        else:
            left = f"{sol_res}"
            right = f"{pred_res}"
        return f"{left}|{right}"

    # multi‑chain / mismatched chains
    if base:
        left = f"{sol_chain}:{sol_res}{base}"
        right = f"{pred_chain}:{pred_res}{base}"
    else:
        left = f"{sol_chain}:{sol_res}"
        right = f"{pred_chain}:{pred_res}"
    return f"{left}|{right}"


def _export_canonical_tsv(df: pd.DataFrame, out_path: Path, puzzle: str) -> bool:
    """
    Re-project interaction features onto a canonical pocket index defined by
    split.txt / xx.index, and export a TSV.

    Returns True if canonical export was performed; False to fall back to
    legacy behavior.
    """
    if pocket_utils is None:
        return False

    sol_stem = _infer_solution_stem(df)
    if not sol_stem:
        return False

    solutions_roots = [
        SCRIPT_ROOT / "Puzzles" / "solution",
        SCRIPT_ROOT / "PuzzlesBACKUP" / "solution",
    ]
    index_roots = [
        SCRIPT_ROOT / "Puzzles",
        SCRIPT_ROOT / "PuzzlesBACKUP",
    ]
    pim = pocket_utils.build_pocket_index_mapping_from_paths(
        puzzle,
        sol_stem,
        solutions_roots=solutions_roots,
        index_roots=index_roots,
    )
    if pim is None or pim.length == 0:
        return False

    # Load per-residue base letters from solution PDB to enrich labels.
    sol_resnames = _load_solution_resnames(puzzle, sol_stem)
    sol_chains = {ch for ch, _ in pim.sol_positions}
    pred_chains = {ch for ch, _ in pim.pred_positions}
    single_chain_mode = (
        len(sol_chains) == 1
        and len(pred_chains) == 1
        and next(iter(sol_chains)) == next(iter(pred_chains))
    )

    cols = list(df.columns)
    feature_cols = [c for c in cols if re.match(r"^\d+:[A-Za-z]#.+$", str(c))]
    # Drop water‑mediated features from aggregation
    feature_cols = [c for c in feature_cols if not str(c).endswith("#Water_mediated")]
    if not feature_cols or 'is_solution' not in df.columns:
        return False

    # Ensure feature values are numeric and treat missing/blank as 0 so that
    # NaN does not get interpreted as a non‑zero interaction.
    df[feature_cols] = df[feature_cols].apply(pd.to_numeric, errors="coerce").fillna(0.0)

    # Parse feature metadata: raw_col -> (resseq, chain, interaction)
    feature_meta = {}
    interaction_types = set()
    for c in feature_cols:
        m = re.match(r"^(\d+):([A-Za-z])#(.+)$", str(c))
        if not m:
            continue
        try:
            resseq = int(m.group(1))
        except Exception:
            continue
        chain = m.group(2)
        itype = m.group(3)
        feature_meta[c] = (resseq, chain, itype)
        interaction_types.add(itype)

    if not feature_meta or not interaction_types:
        return False

    unique_interactions = sorted(interaction_types)

    # Prepare canonical feature columns
    canon_cols = []
    canon_meta = {}
    for idx, (sol_pos, pred_pos) in enumerate(zip(pim.sol_positions, pim.pred_positions)):
        sol_chain, sol_res = sol_pos
        pred_chain, pred_res = pred_pos
        base = _format_pocket_label(
            sol_chain,
            sol_res,
            pred_chain,
            pred_res,
            sol_resnames,
            single_chain_mode,
        )
        for itype in unique_interactions:
            col_name = f"{base}#{itype}"
            canon_cols.append(col_name)
            canon_meta[(idx, itype)] = col_name

    basic = ['Source', 'Ligand_name', 'is_solution']
    for b in basic:
        if b not in df.columns:
            df[b] = 0

    new_df = df[basic].copy()
    for c in canon_cols:
        new_df[c] = 0

    # Row-wise projection from raw feature columns to canonical pocket axis
    for ridx, row in df.iterrows():
        is_sol_flag = False
        try:
            is_sol_flag = int(row.get('is_solution', 0)) == 1
        except Exception:
            is_sol_flag = False

        side_positions = pim.sol_positions if is_sol_flag else pim.pred_positions
        side_map = {(ch, res): i for i, (ch, res) in enumerate(side_positions)}

        for raw_col, meta in feature_meta.items():
            resseq, chain, itype = meta
            try:
                v = float(row.get(raw_col, 0))
            except Exception:
                continue
            if v == 0:
                continue
            canon_idx = side_map.get((chain, resseq))
            if canon_idx is None:
                continue
            col_name = canon_meta.get((canon_idx, itype))
            if not col_name:
                continue
            new_df.at[ridx, col_name] = 1

    out_cols = basic + canon_cols
    out_df = new_df[out_cols]
    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_df.to_csv(out_path, sep='\t', index=False)
    print(f"Wrote canonical TSV with {out_df.shape[0]} rows and {out_df.shape[1]} columns -> {out_path}")
    return True


def main():
    ap = argparse.ArgumentParser(description="Export heatmap TSV from per‑puzzle Excel interactions sheet")
    ap.add_argument('--xlsx', required=True, type=Path, help='Per‑puzzle Excel file (…_fingernaat_results.xlsx)')
    ap.add_argument('--sheet', default='interactions', help='Sheet name with interaction rows (default: interactions)')
    ap.add_argument('--out', required=True, type=Path, help='Output TSV path')
    args = ap.parse_args()

    df = pd.read_excel(args.xlsx, sheet_name=args.sheet)
    # Normalize feature column names
    df = normalize_feature_columns(df)

    # Ensure required columns
    if 'Ligand_name' not in df.columns:
        # Prefer ligand_dirname if present; otherwise synthesize from metadata
        if 'ligand_dirname' in df.columns:
            df['Ligand_name'] = df['ligand_dirname']
        else:
            df['Ligand_name'] = df.apply(lambda r: f"{r.get('resname','')}{r.get('chain','')}{r.get('resseq','')}", axis=1)
    if 'Source' not in df.columns:
        df['Source'] = df.apply(build_source_label, axis=1)

    puzzle = _infer_puzzle_from_xlsx(args.xlsx, df)

    # Try canonical pocket-axis export first; on failure, fall back to legacy behavior.
    if _export_canonical_tsv(df.copy(), args.out, puzzle):
        return

    # Legacy export: keep Source and optional basics first, then raw feature columns
    basic = ['Source', 'Ligand_name', 'is_solution']
    cols = list(df.columns)
    feature_cols = [c for c in cols if re.match(r"^\d+:[A-Za-z]#.+$", str(c))]
    # Drop water‑mediated features from legacy export as well
    feature_cols = [c for c in feature_cols if not str(c).endswith("#Water_mediated")]
    out_cols = basic + [c for c in cols if c in feature_cols]
    out_df = df[out_cols]

    for c in feature_cols:
        out_df[c] = pd.to_numeric(out_df[c], errors='coerce').fillna(0).astype(int)

    args.out.parent.mkdir(parents=True, exist_ok=True)
    out_df.to_csv(args.out, sep='\t', index=False)
    print(f"Wrote TSV with {out_df.shape[0]} rows and {out_df.shape[1]} columns -> {args.out}")


if __name__ == '__main__':
    main()
